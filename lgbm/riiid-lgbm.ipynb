{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# Used most of coding from this kernel https://www.kaggle.com/lgreig/simple-lgbm-baseline\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train= pd.read_csv('../input/riiid-test-answer-prediction/train.csv',\n                usecols=[1, 2, 3,4,7,8,9], dtype={'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8','prior_question_elapsed_time': 'float32','prior_question_had_explanation': 'boolean'}\n              )\ntrain = train[train.content_type_id == False]\n#arrange by timestamp\ntrain = train.sort_values(['timestamp'], ascending=True)\n\ntrain.drop(['timestamp','content_type_id'], axis=1,   inplace=True)\n\nresults_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content\"]\n\nresults_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\nresults_u.columns = [\"answered_correctly_user\", 'sum']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"X = train.iloc[90000000:,:]\nX = pd.merge(X, results_u, on=['user_id'], how=\"left\")\nX = pd.merge(X, results_c, on=['content_id'], how=\"left\")\nX=X[X.answered_correctly!= -1 ]\nX=X.sort_values(['user_id'])\nY = X[[\"answered_correctly\"]]\nX = X.drop([\"answered_correctly\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\nX[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(X[\"prior_question_had_explanation\"])\nX.head()\n\nX = X[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']] \nX.fillna(0.5,  inplace=True)\nfrom  sklearn.tree import DecisionTreeClassifier\nfrom  sklearn.model_selection import train_test_split\nXt, Xv, Yt, Yv = train_test_split(X, Y, test_size = 0.01, shuffle=False)\n\nimport lightgbm as lgb\n\nparams = {\n    'objective': 'binary',\n    'max_bin': 600,\n    'learning_rate': 0.01,\n    'num_leaves': 80\n}\n\n\nlgb_train = lgb.Dataset(Xt, Yt)\nlgb_eval = lgb.Dataset(Xv, Yv, reference=lgb_train)\n\nmodel = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=10,\n    num_boost_round=10000,\n    early_stopping_rounds=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred = model.predict(Xv)\ny_true = np.array(Yv)\nroc_auc_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test =  pd.read_csv('../input/riiid-test-answer-prediction/example_test.csv')\ntest[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test[\"prior_question_had_explanation\"])\ntest = pd.merge(test, results_u, on=['user_id'],  how=\"left\")\ntest = pd.merge(test, results_c, on=['content_id'],  how=\"left\")\ntest[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']]\ntest.fillna(0.5, inplace=True)\n\ny_pred = model.predict(test[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']])\n\ntest['answered_correctly'] = y_pred\n\nresults_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content\"]\n\nresults_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum'])\nresults_u.columns = [\"answered_correctly_user\", 'sum']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import riiideducation\nenv = riiideducation.make_env()\niter_test = env.iter_test()\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, results_u, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_c, on=['content_id'],  how=\"left\")\n    test_df['answered_correctly_user'].fillna(0.5, inplace=True)\n    test_df['answered_correctly_content'].fillna(0.5, inplace=True)\n    test_df['sum'].fillna(0, inplace=True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = lb_make.fit_transform(test_df[\"prior_question_had_explanation\"])\n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'answered_correctly_content', 'sum','prior_question_elapsed_time','prior_question_had_explanation_enc']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}