{"cells":[{"source":["This is an implementation of SAINT model.\n","\n","Reference:\n","\n","1. https://arxiv.org/abs/2002.07033\n","2. https://www.kaggle.com/claverru/demystifying-transformers-let-s-make-it-public/execution"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","def get_question_df(path_questions):\n","    dtype_questions = {\n","        \"question_id\": \"int32\",\n","        # 'bundle_id': 'int32',\n","        # 'correct_answer': 'int8',\n","        \"part\": \"int8\",\n","        # 'tags': 'object',\n","    }\n","    questions = pd.read_csv(\n","        path_questions,\n","        dtype=dtype_questions,\n","        usecols=dtype_questions.keys(),\n","        index_col=\"question_id\",\n","    )\n","    return questions\n","\n","\n","def get_train_df(path_train):\n","    dtype = {\n","        \"answered_correctly\": \"int8\",\n","        # 'row_id': 'int64',\n","        # 'timestamp': 'int64',\n","        \"user_id\": \"int32\",\n","        \"content_id\": \"int16\",\n","        # 'content_type_id': 'int8',\n","        \"task_container_id\": \"int16\",\n","        # 'user_answer': 'int8',\n","        \"prior_question_elapsed_time\": \"float32\",\n","        # 'prior_question_had_explanation': 'boolean'\n","    }\n","    df = pd.read_csv(path_train, usecols=dtype.keys(), dtype=dtype, nrows=10 ** 6)\n","    df = df[df.answered_correctly != -1]\n","    df = df.groupby(\"user_id\").head(1500)\n","    return df\n","\n","\n","def transform_questions(questions):\n","    part_ids = questions.part.max() + 1\n","    return questions, part_ids\n","\n","\n","def transform_df(df, questions):\n","    df[\"prior_question_elapsed_time\"] = (\n","        df[\"prior_question_elapsed_time\"].fillna(0).astype(np.float32) / 300000\n","    )\n","    content_ids = questions.index.max() + 2\n","    df = df.join(questions, on=\"content_id\")\n","    df[\"content_id\"] += 1\n","    df[\"task_container_id\"] += 1\n","    task_container_ids = 10001\n","    return df, content_ids, task_container_ids\n","\n","\n","def get_df(path_questions, path_train):\n","\n","    questions = get_question_df(path_questions)\n","    df = get_train_df(path_train)\n","\n","    questions, part_ids = transform_questions(questions)\n","    df, content_ids, task_container_ids = transform_df(df, questions)\n","\n","    df = {uid: u.drop(columns=\"user_id\") for uid, u in df.groupby(\"user_id\")}\n","    return df, part_ids, content_ids, task_container_ids\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","\n","# [1,2,3,4] --- w = 2 --[[1,2], [2,3], [3,4]] but 2D to 3D\n","\n","\n","def rolling_window(a, w):\n","    s0, s1 = a.strides\n","    m, n = a.shape\n","    return np.lib.stride_tricks.as_strided(\n","        a, shape=(m - w + 1, w, n), strides=(s0, s0, s1)\n","    )\n","\n","\n","def make_time_series(x, windows_size):\n","    x = np.pad(x, [[windows_size - 1, 0], [0, 0]], constant_values=0)\n","    x = rolling_window(x, windows_size)\n","    return x\n","\n","\n","def add_features_to_user(user):\n","    # We add one to the column in order to have zeros as padding values\n","    # Start Of Sentence (SOS) token will be 3.\n","    user[\"answered_correctly\"] = user[\"answered_correctly\"].shift(fill_value=2) + 1\n","    return user\n","\n","\n","class RiidSequence(tf.keras.utils.Sequence):\n","    def __init__(self, users, windows_size, batch_size=256, start=0, end=None):\n","        self.users = users  # {'user_id': user_df, ...}\n","        self.windows_size = windows_size\n","        # to convert indices to our keys\n","        self.mapper = dict(zip(range(len(users)), users.keys()))\n","        # start and end to easy generate training and validation\n","        self.start = start\n","        self.end = end if end else len(users)\n","        # To know where the answered_correctly_column is\n","        self.answered_correctly_index = list(self.user_example().columns).index(\n","            \"answered_correctly\"\n","        )\n","\n","    def __len__(self):\n","        return self.end - self.start\n","\n","    def __getitem__(self, idx):\n","        uid = self.mapper[idx + self.start]\n","        user = self.users[uid].copy()\n","        y = user[\"answered_correctly\"].to_numpy().copy()\n","        x = add_features_to_user(user)\n","        return make_time_series(x, self.windows_size), y\n","\n","    def user_example(self):\n","        \"\"\"Just to check what we have till' now.\"\"\"\n","        uid = self.mapper[self.start]\n","        return add_features_to_user(self.users[uid].copy())\n","\n","    # INFERENCE PART\n","    def get_user_for_inference(self, user_row):\n","        \"\"\"Picks a new user row and concats it to previous interactions\n","        if it was already stored.\n","\n","        Maybe the biggest trick in the notebook is here. We reuse the user_id column to\n","        insert the answered_correctly SOS token because we previously placed the column\n","        there on purpose.\n","\n","        After it, we roll that column and then crop it if it was bigger than the window\n","        size, making the SOS token disapear if out of the sequence.\n","\n","        If the sequence if shorter than the window size, then we pad it.\n","        \"\"\"\n","        uid = user_row[self.answered_correctly_index]\n","        user_row[self.answered_correctly_index] = 2  # SOS token\n","        user_row = user_row[np.newaxis, ...]\n","        if uid in self.users:\n","            x = np.concatenate([self.users[uid], user_row])\n","            # same as in training, we need to add one!!!\n","            x[:, self.answered_correctly_index] = (\n","                np.roll(x[:, self.answered_correctly_index], 1) + 1\n","            )\n","        else:\n","            x = user_row\n","\n","        if x.shape[0] < self.windows_size:\n","            return np.pad(x, [[self.windows_size - x.shape[0], 0], [0, 0]])\n","        elif x.shape[0] > self.windows_size:\n","            return x[-self.windows_size :]\n","        else:\n","            return x\n","\n","    def update_user(self, uid, user):\n","        \"\"\"Concat the new user's interactions to the old ones if already stored.\"\"\"\n","        if uid in self.users:\n","            self.users[uid] = np.concatenate([self.users[uid], user])[\n","                -self.windows_size :\n","            ]\n","        else:\n","            self.users[uid] = user\n","\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(\n","        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n","    )\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","\n","# NN THINGS\n","\n","\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","    if mask is not None:\n","        scaled_attention_logits += mask * -1e9\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    output = tf.matmul(attention_weights, v)\n","    return output, attention_weights\n","\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask\n","        )\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","        output = self.dense(concat_attention)\n","\n","        return output, attention_weights\n","\n","\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential(\n","        [tf.keras.layers.Dense(dff, activation=\"relu\"), tf.keras.layers.Dense(d_model)]\n","    )\n","\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","\n","        return out2\n","\n","\n","def create_padding_mask(seqs):\n","    # We mask only those vectors of the sequence in which we have all zeroes\n","    # (this is more scalable for some situations).\n","    mask = tf.cast(tf.reduce_all(tf.math.equal(seqs, 0), axis=-1), tf.float32)\n","    # (batch_size, 1, 1, seq_len)\n","    return mask[:, tf.newaxis, tf.newaxis, :]\n","\n","\n","def get_series_model(\n","    n_features,\n","    content_ids,\n","    task_container_ids,\n","    part_ids,\n","    windows_size=64,\n","    d_model=24,\n","    num_heads=4,\n","    n_encoder_layers=2,\n","):\n","    # Input\n","    inputs = tf.keras.Input(shape=(windows_size, n_features), name=\"inputs\")\n","    mask = create_padding_mask(inputs)\n","    pos_enc = positional_encoding(windows_size, d_model)\n","\n","    # Divide branches\n","    content_id = inputs[..., 0]\n","    task_container_id = inputs[..., 1]\n","    answered_correctly = inputs[..., 2]\n","    elapsed_time = inputs[..., 3]\n","    part = inputs[..., 4]\n","\n","    # Create embeddings\n","    content_embeddings = tf.keras.layers.Embedding(content_ids, d_model)(content_id)\n","    task_embeddings = tf.keras.layers.Embedding(task_container_ids, d_model)(\n","        task_container_id\n","    )\n","    answered_correctly_embeddings = tf.keras.layers.Embedding(4, d_model)(\n","        answered_correctly\n","    )\n","    # Continuous! Only a learnable layer for it.\n","    elapsed_time_embeddings = tf.keras.layers.Dense(d_model, use_bias=False)(\n","        elapsed_time\n","    )\n","    part_embeddings = tf.keras.layers.Embedding(part_ids, d_model)(part)\n","\n","    # Add embeddings\n","    x = tf.keras.layers.Add()(\n","        [\n","            pos_enc,\n","            content_embeddings,\n","            task_embeddings,\n","            answered_correctly_embeddings,\n","            elapsed_time_embeddings,\n","            part_embeddings,\n","        ]\n","    )\n","\n","    for _ in range(n_encoder_layers):\n","        x = EncoderLayer(\n","            d_model=d_model, num_heads=num_heads, dff=d_model * 4, rate=0.1\n","        )(x, mask=mask)\n","\n","    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n","    x = tf.keras.layers.Dropout(0.2)(x)\n","    output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n","    return tf.keras.Model(inputs, output, name=\"model\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","\n","path_questions = \"../input/riiid-test-answer-prediction/questions.csv\"\n","path_train = \"../input/riiid-test-answer-prediction/train.csv\"\n","df, part_ids, content_ids, task_container_ids = get_df(path_questions, path_train)\n","\n","train_idx = int(len(df) * 0.8)\n","windows_size = 64\n","epochs = 300\n","patience = 2\n","d_model = 32\n","num_heads = 4\n","n_encoder_layers = 2\n","\n","s_train = RiidSequence(df, windows_size, start=0, end=train_idx)\n","s_val = RiidSequence(df, windows_size, start=train_idx)\n","\n","n_features = s_train[0][0].shape[-1]\n","\n","tf.keras.backend.clear_session()\n","model = get_series_model(\n","    n_features,\n","    content_ids,\n","    task_container_ids,\n","    part_ids,\n","    windows_size=windows_size,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    n_encoder_layers=n_encoder_layers,\n",")\n","\n","model.compile(\n","    optimizer=\"adam\",\n","    loss=\"binary_crossentropy\",\n","    metrics=[\n","        tf.keras.metrics.AUC(name=\"AUC\"),\n","        tf.keras.metrics.BinaryAccuracy(name=\"acc\"),\n","    ],\n",")\n","\n","# tf.keras.utils.plot_model(model)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","  34/3059 [..............................] - ETA: 24:12 - loss: 0.7798 - AUC: 0.4819 - acc: 0.5069Process Keras_worker_ForkPoolWorker-1:\n","Process Keras_worker_ForkPoolWorker-2:\n","Process Keras_worker_ForkPoolWorker-4:\n","Process Keras_worker_ForkPoolWorker-3:\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n","    task = get()\n","  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n","    task = get()\n","  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n","    task = get()\n","  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n","    task = get()\n","  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n","    buf = self._recv(4)\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-192162534367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0ms_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","\n","model.fit(\n","    s_train,\n","    validation_data=s_val,\n","    epochs=epochs,\n","    workers=4,\n","    shuffle=True,\n","    use_multiprocessing=True,\n","    callbacks=tf.keras.callbacks.EarlyStopping(\n","        patience=patience, monitor=\"val_AUC\", mode=\"max\", restore_best_weights=True\n","    ),\n","    verbose=1,\n",")\n","model.save_weights(\"model.h5\")\n"]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit","metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}}},"nbformat":4,"nbformat_minor":4}